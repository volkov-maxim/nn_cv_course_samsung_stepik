{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMzdMlWHjeN80RcPCfhD/HK"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "nQGVFrxodeHJ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Сперва создадим тензор x:\n",
        "x = torch.tensor([[10., 20.]])\n",
        "print(\"x\", x.shape)\n",
        "\n",
        "# Оригинальный полносвязный слой с 2-мя входами и 3-мя нейронами (выходами):\n",
        "fc = torch.nn.Linear(2, 3)\n",
        "\n",
        "# Веса fc-слоя хранятся в fc.weight, а bias'ы соответственно в fc.bias\n",
        "# fc.weight и fc.bias по умолчанию инициализируются случайными числами\n",
        "\n",
        "# Давайте проставим свои значения в веса и bias'ы:\n",
        "w = torch.tensor([[11., 12.], [21., 22.], [31., 32]])\n",
        "print(\"w\", w.shape)\n",
        "print(\"w.T\", w.transpose(0,1).shape)\n",
        "fc.weight.data = w\n",
        "\n",
        "b = torch.tensor([[31., 32., 33.]])\n",
        "print(\"b\", b.shape)\n",
        "fc.bias.data = b\n",
        "\n",
        "# Получим выход fc-слоя:\n",
        "fc_out = fc(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uh1Ut96xdnuv",
        "outputId": "8325fc1a-0285-48d5-ddd8-8a13b03bbb5a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x torch.Size([1, 2])\n",
            "w torch.Size([3, 2])\n",
            "w.T torch.Size([2, 3])\n",
            "b torch.Size([1, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MXuTo_lHYEB1",
        "outputId": "1ec105ab-e859-4960-8c09-0c7ceff69973"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x * w.T torch.Size([1, 3])\n",
            "tensor([[True, True, True]])\n"
          ]
        }
      ],
      "source": [
        "# Попробуем теперь получить аналогичные выходы с помощью матричного перемножения:\n",
        "print(\"x * w.T\", torch.matmul(x, w.transpose(0, 1)).shape)\n",
        "fc_out_alternative =  torch.add(torch.matmul(x, w.transpose(0, 1)), b) # x * w^T + b\n",
        "\n",
        "# Проверка осуществляется автоматически вызовом функции\n",
        "print(fc_out == fc_out_alternative)\n",
        "# (раскомментируйте, если решаете задачу локально)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Просуммируем выход fc-слоя, чтобы получить скаляр:\n",
        "fc_out_summed = fc_out.sum()\n",
        "print(\"fc_out_summed\", fc_out_summed)\n",
        "\n",
        "# Посчитаем градиенты формулы fc_out_summed:\n",
        "fc_out_summed.backward()\n",
        "weight_grad = fc.weight.grad\n",
        "bias_grad = fc.bias.grad\n",
        "\n",
        "# Ok, теперь воспроизведем вычисления выше но без fc-слоя:\n",
        "# Проставим, что у \"w\" и \"b\" нужно вычислять градиенты (для fc-слоя это произошло автоматически):\n",
        "w.requires_grad_(True)\n",
        "b.requires_grad_(True)\n",
        "\n",
        "# Получим выход нашей формулы:\n",
        "our_formula = torch.add(torch.matmul(x, w.transpose(0, 1)), b).sum() # SUM{x * w^T + b}\n",
        "print(\"our_formula\", our_formula)\n",
        "# Сделайте backward для нашей формулы:\n",
        "our_formula.backward()\n",
        "\n",
        "# Проверка осуществляется автоматически, вызовом функций:\n",
        "print('fc_weight_grad:', weight_grad)\n",
        "print('our_weight_grad:', w.grad)\n",
        "print('fc_bias_grad:', bias_grad)\n",
        "print('out_bias_grad:', b.grad)\n",
        "# (раскомментируйте, если работаете над задачей локально)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PQVDD3hdbhB",
        "outputId": "0fa1b238-ea0e-4e03-f477-9d382c24ebc2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fc_out_summed tensor(2046., grad_fn=<SumBackward0>)\n",
            "our_formula tensor(2046., grad_fn=<SumBackward0>)\n",
            "fc_weight_grad: tensor([[10., 20.],\n",
            "        [10., 20.],\n",
            "        [10., 20.]])\n",
            "our_weight_grad: tensor([[10., 20.],\n",
            "        [10., 20.],\n",
            "        [10., 20.]])\n",
            "fc_bias_grad: tensor([[1., 1., 1.]])\n",
            "out_bias_grad: tensor([[1., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PUIwU8bSerbL"
      },
      "execution_count": 16,
      "outputs": []
    }
  ]
}